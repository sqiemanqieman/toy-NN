{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class MLQPLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_outputs):\n",
    "        super(MLQPLayer, self).__init__()\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight('mu', shape=[int(input_shape[-1]), self.n_outputs])\n",
    "        self.nu = self.add_weight('nu', shape=[int(input_shape[-1]), self.n_outputs])\n",
    "        self.bias = self.add_weight('bias', shape=[1, self.n_outputs])\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return tf.matmul(inputs*inputs, self.mu) + tf.matmul(inputs, self.nu) + self.bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 5000\n",
    "display_step = 100\n",
    "n_idle_epochs = 1000\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=n_idle_epochs, min_delta=0.00001)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if lr <= 0.01:\n",
    "        return lr\n",
    "    if epoch % 200 == 0:\n",
    "        return lr * 0.8\n",
    "        # return lr * 0.9   # best\n",
    "    else:\n",
    "        return lr\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "class NEPOCHLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, per_epoch=100):\n",
    "        super(NEPOCHLogger, self).__init__()\n",
    "        self.seen = 0\n",
    "        self.per_epoch = per_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.per_epoch == 0:\n",
    "            print('Epoch {}, loss {:.8f}, mae {:.8f}'.format(epoch, logs['loss'], logs['mae']))\n",
    "\n",
    "log_display = NEPOCHLogger(per_epoch=display_step)\n",
    "train_data = pd.read_csv(r'../two_spiral_train_data.txt', header=None, sep='\\s+')\n",
    "test_data = pd.read_csv(r'../two_spiral_test_data.txt', header=None, sep='\\s+')\n",
    "train_data['class_0'] = train_data[2].apply(lambda x: 1 if x == 0 else 0)\n",
    "train_data['class_1'] = train_data[2].apply(lambda x: 1 if x == 1 else 0)\n",
    "test_data['class_0'] = test_data[2].apply(lambda x: 1 if x == 0 else 0)\n",
    "test_data['class_1'] = test_data[2].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "train_X = tf.convert_to_tensor(np.asarray(train_data.iloc[:, 0:2]))\n",
    "train_y = tf.convert_to_tensor(np.asarray(train_data.iloc[:, 2]))\n",
    "test_X = tf.convert_to_tensor(np.asarray(test_data.iloc[:, 0:2]))\n",
    "test_y = tf.convert_to_tensor(np.asarray(test_data.iloc[:, 2]))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    MLQPLayer(128),\n",
    "    tf.keras.layers.Activation('sigmoid'),\n",
    "    MLQPLayer(1),\n",
    "    tf.keras.layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 0.11969971, mae 0.28002807\n",
      "Epoch 100, loss 0.11886550, mae 0.27705985\n",
      "Epoch 200, loss 0.11845338, mae 0.27707309\n",
      "Epoch 300, loss 0.11663048, mae 0.27355358\n",
      "Epoch 400, loss 0.11618815, mae 0.27182603\n",
      "Epoch 500, loss 0.11498250, mae 0.27024233\n",
      "Epoch 600, loss 0.11392422, mae 0.26800534\n",
      "Epoch 700, loss 0.11350966, mae 0.26729012\n",
      "Epoch 800, loss 0.11216521, mae 0.26412344\n",
      "Epoch 900, loss 0.11132056, mae 0.26237214\n",
      "Epoch 1000, loss 0.11089906, mae 0.26128709\n",
      "Epoch 1100, loss 0.10905825, mae 0.25897470\n",
      "Epoch 1200, loss 0.10894249, mae 0.25740111\n",
      "Epoch 1300, loss 0.10757547, mae 0.25482249\n",
      "Epoch 1400, loss 0.10693696, mae 0.25323981\n",
      "Epoch 1500, loss 0.10616215, mae 0.25163886\n",
      "Epoch 1600, loss 0.10486536, mae 0.24984159\n",
      "Epoch 1700, loss 0.10527906, mae 0.24992965\n",
      "Epoch 1800, loss 0.10365067, mae 0.24725634\n",
      "Epoch 1900, loss 0.10229364, mae 0.24411871\n",
      "Epoch 2000, loss 0.10238693, mae 0.24468498\n",
      "Epoch 2100, loss 0.10193303, mae 0.24245578\n",
      "Epoch 2200, loss 0.10140450, mae 0.24264921\n",
      "Epoch 2300, loss 0.09996343, mae 0.23969126\n",
      "Epoch 2400, loss 0.09837282, mae 0.23724848\n",
      "Epoch 2500, loss 0.09851336, mae 0.23704748\n",
      "Epoch 2600, loss 0.09812813, mae 0.23535128\n",
      "Epoch 2700, loss 0.09787354, mae 0.23453954\n",
      "Epoch 2800, loss 0.09623725, mae 0.23191452\n",
      "Epoch 2900, loss 0.09581785, mae 0.23110209\n",
      "Epoch 3000, loss 0.09499339, mae 0.22983958\n",
      "Epoch 3100, loss 0.09449883, mae 0.22812361\n",
      "Epoch 3200, loss 0.09305763, mae 0.22610998\n",
      "Epoch 3300, loss 0.09276449, mae 0.22522591\n",
      "Epoch 3400, loss 0.09158048, mae 0.22369115\n",
      "Epoch 3500, loss 0.09208386, mae 0.22350436\n",
      "Epoch 3600, loss 0.09115511, mae 0.22149108\n",
      "Epoch 3700, loss 0.09097784, mae 0.22122081\n",
      "Epoch 3800, loss 0.08970180, mae 0.21837482\n",
      "Epoch 3900, loss 0.08900387, mae 0.21763301\n",
      "Epoch 4000, loss 0.08824695, mae 0.21678510\n",
      "Epoch 4100, loss 0.08756568, mae 0.21575376\n",
      "Epoch 4200, loss 0.08668327, mae 0.21423164\n",
      "Epoch 4300, loss 0.08629041, mae 0.21396764\n",
      "Epoch 4400, loss 0.08532181, mae 0.21159232\n",
      "Epoch 4500, loss 0.08449631, mae 0.21136399\n",
      "Epoch 4600, loss 0.08430388, mae 0.21036300\n",
      "Epoch 4700, loss 0.08353519, mae 0.20922333\n",
      "Epoch 4800, loss 0.08268424, mae 0.20741458\n",
      "Epoch 4900, loss 0.08247142, mae 0.20681620\n",
      "Train Finished! <keras.callbacks.History object at 0x000001DAD149D570>\n",
      "total number of test samples: 300\n",
      "[0.20581302046775818, 0.33409053087234497]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, epochs=training_epochs, verbose=0, batch_size=16, callbacks=[log_display])\n",
    "print(\"Train Finished!\", history)\n",
    "y_hat_train = model.predict(train_X, verbose=0)\n",
    "y_hat_test = model.predict(test_X, verbose=0)\n",
    "print('total number of test samples: %d' % len(test_y))\n",
    "print(model.evaluate(test_X, test_y, verbose=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m6.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m y \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m6.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m):\n\u001B[1;32m----> 4\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.5\u001B[39m:\n\u001B[0;32m      5\u001B[0m             class_1_area\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m, [])\u001B[38;5;241m.\u001B[39mappend(x)\n\u001B[0;32m      6\u001B[0m             class_1_area\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m, [])\u001B[38;5;241m.\u001B[39mappend(y)\n",
      "File \u001B[1;32mC:\\ProgramFiles\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mC:\\ProgramFiles\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2346\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2344\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_predict_begin()\n\u001B[0;32m   2345\u001B[0m batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2346\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, iterator \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39menumerate_epochs():  \u001B[38;5;66;03m# Single epoch.\u001B[39;00m\n\u001B[0;32m   2347\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[0;32m   2348\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n",
      "File \u001B[1;32mC:\\ProgramFiles\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1304\u001B[0m, in \u001B[0;36mDataHandler.enumerate_epochs\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1302\u001B[0m \u001B[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001B[39;00m\n\u001B[0;32m   1303\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncate_execution_to_epoch():\n\u001B[1;32m-> 1304\u001B[0m     data_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1305\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial_epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_epochs):\n\u001B[0;32m   1306\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramFiles\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[1;32m--> 499\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    501\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    502\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramFiles\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:703\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[1;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[0;32m    699\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    701\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    702\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 703\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32mC:\\ProgramFiles\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:742\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    739\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fulltype\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\n\u001B[0;32m    740\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types)\n\u001B[0;32m    741\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource\u001B[38;5;241m.\u001B[39mop\u001B[38;5;241m.\u001B[39mexperimental_set_type(fulltype)\n\u001B[1;32m--> 742\u001B[0m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramFiles\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3439\u001B[0m, in \u001B[0;36mmake_iterator\u001B[1;34m(dataset, iterator, name)\u001B[0m\n\u001B[0;32m   3437\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   3438\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3439\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3440\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3442\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "class_0_area, class_1_area = {}, {}\n",
    "for x in np.arange(-6, 6.1, 0.1):\n",
    "    for y in np.arange(-6, 6.1, 0.1):\n",
    "        if model.predict([[x, y]], verbose=0)[0][0] > 0.5:\n",
    "            class_1_area.setdefault('x', []).append(x)\n",
    "            class_1_area.setdefault('y', []).append(y)\n",
    "        else:\n",
    "            class_0_area.setdefault('x', []).append(x)\n",
    "            class_0_area.setdefault('y', []).append(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_0, class_1 = {}, {}\n",
    "for X, y in zip(np.concatenate([train_X.numpy(), test_X.numpy()], 0), np.concatenate([train_y.numpy(), test_y.numpy()], 0)):\n",
    "    if y == 0:\n",
    "        class_0.setdefault('x', []).append(X[0])\n",
    "        class_0.setdefault('y', []).append(X[1])\n",
    "    else:\n",
    "        class_1.setdefault('x', []).append(X[0])\n",
    "        class_1.setdefault('y', []).append(X[1])\n",
    "plt.axes().set_facecolor('gray')\n",
    "plt.plot(class_0_area['x'], class_0_area['y'], 'cs', markersize=3, label='class 0 area')\n",
    "plt.plot(class_1_area['x'], class_1_area['y'], 'ys', markersize=3, label='class 1 area')\n",
    "plt.plot(class_0['x'], class_0['y'], 'wo', markersize=2, label='class 0')\n",
    "plt.plot(class_1['x'], class_1['y'], 'o', markersize=2, color='#000000', label='class 1')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
